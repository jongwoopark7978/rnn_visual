{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "visualization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttw7RMGGw-uz"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUh8Hj6aw6_r"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LI-uqcLwcsk0",
        "outputId": "588e9dcb-6137-4ee8-b896-6a0caba06b78"
      },
      "source": [
        "from google.colab import drive\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os.path as osp \n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cciA5LWl9zi"
      },
      "source": [
        "%cd '/content/drive/My Drive/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition/test_image/'\n",
        "img2 = cv2.imread(\"tree.jpg\", cv2.IMREAD_COLOR)\n",
        "plt.imshow(img2[:,:,::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb_oXJhKgcwF"
      },
      "source": [
        "%%time\n",
        "%cd '/content/'\n",
        "!cp '/content/drive/My Drive/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition/data/ntu/zipped/transformed_data.tgz' 'transformed_data.tgz'\n",
        "%cd '/content/'\n",
        "!tar -xf 'transformed_data.tgz' -C './'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCfPcN6EgatX",
        "outputId": "8b25ac55-419f-4305-df11-55f3a13e8469"
      },
      "source": [
        "%%time\n",
        "save_path = osp.join('/content/ntu/', 'transformed_data')\n",
        "evaluation = 'C-Subject'\n",
        "x_pkl = osp.join(save_path, '%s_x.pkl' % (evaluation))\n",
        "y_pkl = osp.join(save_path, '%s_y.pkl' % (evaluation))\n",
        "with open(x_pkl, 'rb') as f:\n",
        "    train_X = pickle.load(f)\n",
        "with open(y_pkl, 'rb') as f:\n",
        "    train_Y = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 747 ms, sys: 2.76 s, total: 3.51 s\n",
            "Wall time: 24.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0QxjQW3ggLl"
      },
      "source": [
        "print('train_X.shape', train_X.shape, 'train_X[0].shape = ',  train_X[0].shape)\n",
        "print('train_Y.shape =', train_Y.shape)\n",
        "#train_Y includes 59874 samples and each sample is categorized into one of 120 action classes. \n",
        "print('max(train_Y) = ', max(train_Y), 'min(train_Y) =', min(train_Y))\n",
        "print('np.sum(train_Y==5) = ', np.sum(train_Y==5))\n",
        "print('np.sum(train_Y==119) = ', np.sum(train_Y==119))\n",
        "print('train_Y[:20] = ', train_Y[:20])\n",
        "#train_X includes (59874 samples, 57 frames, 150 2 people joint information)\n",
        "#150 joints(3D locations of 25 major body joints=75 * 2 people) == 150\n",
        "print(\"train_X[0][0][:20] = \", train_X[0][0][:20])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS1CkXOdBa--"
      },
      "source": [
        "detail description of the file\r\n",
        "\r\n",
        "For each frame of a skeleton sequence, an actor's 3D positions of 25 joints represented by an 2D array (shape: 25 x 3) is reshaped into a 75-dim vector by concatenating each 3-dim (x, y, z) coordinates along the row dimension in joint order. Each frame contains two actor's joints positions constituting a 150-dim vector. If there is only one actor, then the last 75 values are filled with zeros. Otherwise, select the main actor and the second actor based on the motion amount. Each 150-dim vector as a row vector is put into a 2D numpy array where the number of rows equals the number of valid frames. All such 2D arrays are put into a list and finally the list is serialized into a cPickle file. For the skeleton sequence which contains two or more actors (mostly corresponds to the last 11 classes), the filename and actors' information are recorded into log files. For better understanding, also generate RGB+skeleton videos for visualization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_h-qeNK2ClUx"
      },
      "source": [
        "use .pkl file, 0 means setting  is CV, 1 means the other setting because in each batch, different samples have different sequence_length. padded using 0 to make every sample has max_sequence_length. Then, you need len.pkl to know the originial length of the sequence for each sample \r\n",
        "\r\n",
        "att is attention = (batch_size , sequence_length , 150)\r\n",
        "len is length of each sample in batch = (batch_size, )\r\n",
        "x is inputs = (batch_size , sequence_length , 150)\r\n",
        "y is labels = (batch_size, )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5z66QGHD_aJ",
        "outputId": "0cd7c2b3-4b37-4abf-c30f-dfa6d4792504"
      },
      "source": [
        "%%time\r\n",
        "%cd '/content/'\r\n",
        "!cp '/content/drive/My Drive/View-Adaptive-Neural-Networks-for-Skeleton-based-Human-Action-Recognition/data/ntu/zipped/results_debug1.tgz' 'results_debug1.tgz'\r\n",
        "%cd '/content/'\r\n",
        "!tar -xf 'results_debug1.tgz' -C './'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content\n",
            "CPU times: user 36.4 ms, sys: 15.4 ms, total: 51.9 ms\n",
            "Wall time: 12.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jml8JfGYGFV5"
      },
      "source": [
        "save_path = osp.join('/content/ntu/', 'results_debug1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iqFnCO_FrkJ",
        "outputId": "74b64ec8-7823-4a26-b767-d7da7f37aebd"
      },
      "source": [
        "ls results_debug1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0_att.pkl    0_len.pkl   0_x.pkl    1_best.pth   1_log.csv   1_y.pkl\n",
            "0_best.pth   0_log.csv   0_y.pkl    1_label.txt  1_pred.txt  result.txt\n",
            "0_label.txt  0_pred.txt  1_att.pkl  1_len.pkl    1_x.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqB8GADQETk_"
      },
      "source": [
        "with open('results_debug1/0_x.pkl', 'rb') as f:\r\n",
        "  skeleton_cv_crd = pickle.load(f)\r\n",
        "with open('results_debug1/0_y.pkl', 'rb') as f:\r\n",
        "  skeleton_cv_label = pickle.load(f)\r\n",
        "with open('results_debug1/0_att.pkl', 'rb') as f:\r\n",
        "  skeleton_cv_att = pickle.load(f)\r\n",
        "with open('results_debug1/1_x.pkl', 'rb') as f:\r\n",
        "  skeleton_cs_crd = pickle.load(f)\r\n",
        "with open('results_debug1/1_y.pkl', 'rb') as f:\r\n",
        "  skeleton_cs_label = pickle.load(f)\r\n",
        "with open('results_debug1/1_att.pkl', 'rb') as f:\r\n",
        "  skeleton_cs_att = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHSe6AaghV56"
      },
      "source": [
        "A23. hand waving.\r\n",
        "A34. rub two hands together.\r\n",
        "A36. shake head.\r\n",
        "A44. touch head (headache).\r\n",
        "\r\n",
        "\r\n",
        "A52. pushing other person.\r\n",
        "A56. giving something to other person\r\n",
        "A58. handshaking."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upKXGgFsGctZ"
      },
      "source": [
        "# 1 person action\r\n",
        "# A23==>22. hand waving. (good)\r\n",
        "# A34==>33. rub two hands together.\r\n",
        "# A35==>34. nod head/bow. (good)\r\n",
        "# A36==>35. shake head. (not good)\r\n",
        "# A44==>43. touch head (good)\r\n",
        "# 2 people action\r\n",
        "# A52==>51. pushing other person.\r\n",
        "# A56==>55. giving something to other person\r\n",
        "# A58==>57. handshaking.\r\n",
        "\r\n",
        "candidates = [22, 33, 34, 35, 43, 51, 55, 57]\r\n",
        "print('cv case')\r\n",
        "for idx, value in enumerate(skeleton_cv_label):\r\n",
        "  if value in candidates:\r\n",
        "    print(\"idx = {}, value ={}\".format(idx, value))\r\n",
        "\r\n",
        "print('cs case')\r\n",
        "for idx, value in enumerate(skeleton_cs_label):\r\n",
        "  if value in candidates:\r\n",
        "    print(\"idx = {}, value ={}\".format(idx, value))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XiaPkAHwGw5"
      },
      "source": [
        "with open('results_debug1/0_label.txt', 'rb') as f:\r\n",
        "  for i in range(100):\r\n",
        "    print(f.readline())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0g7I52LZGUn3",
        "outputId": "644745bb-5407-4c46-c1a2-bf8733ad93a0"
      },
      "source": [
        "print('skeleton_cv_crd.shape ={}, skeleton_cv_label.shape={}, skeleton_cv_att.shape={}'.format(skeleton_cv_crd.shape, skeleton_cv_label.shape, skeleton_cv_att.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "skeleton_cv_crd.shape =(256, 233, 150), skeleton_cv_label.shape=(256,), skeleton_cv_att.shape=(256, 233, 150)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6RTS86JMask"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from IPython import display\n",
        "from time import sleep\n",
        "\n",
        "%cd '/content/drive/My Drive/Computer_Vision_CSE527/project/jongwoo_rnn_vis/'\n",
        "img1 = cv2.imread('fruits.jpg', cv2.IMREAD_COLOR)\n",
        "plt.imshow(img1[:,:,::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V79tioSQQR7k"
      },
      "source": [
        "SsssCcccPpppRrrrAaaa (e.g., S001C002P003R002A013), in which sss is the setup number, ccc is the camera ID, ppp is the performer (subject) ID, rrr is the replication number (1 or 2), and aaa is the action class label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qw2MrEVdysu8"
      },
      "source": [
        "trunk_joints = [0, 1, 20, 2, 3]\n",
        "arm_joints = [23, 24, 11, 10, 9, 8, 20, 4, 5, 6, 7, 22, 21]\n",
        "leg_joints = [19, 18, 17, 16, 0, 12, 13, 14, 15]\n",
        "skeletons_in_body = [trunk_joints, arm_joints, leg_joints]\n",
        "\n",
        "# skeleton animation for NTU-3D\n",
        "class Draw3DSkeleton(object):    \n",
        "    def __init__(self, file, save_path=None, init_horizon=-45,\n",
        "                 init_vertical=20, x_rotation=None,\n",
        "                 y_rotation=None, pause_step=0.2, is_file_txt=True):\n",
        "\n",
        "        self.save_path = save_path\n",
        "        self.arranged_xyz = None\n",
        "        self.xyz = None\n",
        "        self.file = None\n",
        "\n",
        "        #file is inserted\n",
        "        if is_file_txt:\n",
        "          self.file = file\n",
        "          if not os.path.exists(self.save_path):\n",
        "              os.mkdir(self.save_path)\n",
        "          #  self.xyz[#coordinate, #frames, #joints, #people]\n",
        "          self.xyz = self.read_xyz(self.file)\n",
        "          self.num_coordinate = self.xyz.shape[0]\n",
        "          self.num_frame = self.xyz.shape[1]\n",
        "          self.num_joints = self.xyz.shape[2]\n",
        "          self.num_people = self.xyz.shape[3]\n",
        "\n",
        "          self.init_horizon = init_horizon\n",
        "          self.init_vertical = init_vertical\n",
        "\n",
        "          self.x_rotation = x_rotation\n",
        "          self.y_rotation = y_rotation\n",
        "\n",
        "          self._pause_step = pause_step\n",
        "\n",
        "          self.relative_response = None\n",
        "          self.scaled_relative_response = None\n",
        "        #array is inserted\n",
        "        else:\n",
        "          #self.arranged_xyz should have [body, #frames, #joints, #coordinate]\n",
        "          #file has [seq, 150 coordinates]\n",
        "          body1 = data_from_net[:,:75]\n",
        "          body2 = data_from_net[:,75:]\n",
        "          body1 = body1.reshape(-1, 25, 3)\n",
        "          body2 = body2.reshape(-1, 25, 3)\n",
        "          empty_body = np.zeros(body2.shape)\n",
        "          if np.allclose(body2, empty_body): \n",
        "            print('body2 is empty')\n",
        "            self.arranged_xyz = body1[np.newaxis, ...]\n",
        "          else:           \n",
        "            print('body2 exists')\n",
        "            self.arranged_xyz = np.concatenate((body1, body2), axis=0).reshape(2, -1, 25, 3)\n",
        "          print('arranged_xyz.shape = ', self.arranged_xyz.shape)\n",
        "          self.num_coordinate = self.arranged_xyz.shape[3]\n",
        "          self.num_frame = self.arranged_xyz.shape[1]\n",
        "          self.num_joints = self.arranged_xyz.shape[2]\n",
        "          self.num_people = self.arranged_xyz.shape[0]\n",
        "\n",
        "          self.init_horizon = init_horizon\n",
        "          self.init_vertical = init_vertical\n",
        "\n",
        "          self.x_rotation = x_rotation\n",
        "          self.y_rotation = y_rotation\n",
        "\n",
        "          self._pause_step = pause_step\n",
        "\n",
        "          self.relative_response = None\n",
        "          self.scaled_relative_response = None\n",
        "\n",
        "\n",
        "    def _read_skeleton(self, file):\n",
        "        with open(file, 'r') as f:\n",
        "            skeleton_sequence = {}\n",
        "            skeleton_sequence['numFrame'] = int(f.readline())\n",
        "            #81 frames (it looks correct)\n",
        "            # print('skeleton_sequence[numFrame] =' , skeleton_sequence['numFrame'])\n",
        "            skeleton_sequence['frameInfo'] = []\n",
        "            for t in range(skeleton_sequence['numFrame']):\n",
        "                frame_info = {}\n",
        "                frame_info['numBody'] = int(f.readline())\n",
        "                frame_info['bodyInfo'] = []\n",
        "                for m in range(frame_info['numBody']):\n",
        "                    body_info = {}\n",
        "                    #numbers on the first line. 72057594037940044 0 1 1 1 1 0 -0.07373063 -0.1171718 2\n",
        "                    body_info_key = [\n",
        "                        'bodyID', 'clipedEdges', 'handLeftConfidence',\n",
        "                        'handLeftState', 'handRightConfidence', 'handRightState',\n",
        "                        'isResticted', 'leanX', 'leanY', 'trackingState'\n",
        "                    ]\n",
        "                    body_info = {\n",
        "                        k: float(v)\n",
        "                        for k, v in zip(body_info_key, f.readline().split())\n",
        "                    }\n",
        "                    body_info['numJoint'] = int(f.readline())\n",
        "                    body_info['jointInfo'] = []\n",
        "                    for v in range(body_info['numJoint']):\n",
        "                        joint_info_key = [\n",
        "                            'x', 'y', 'z', 'depthX', 'depthY', 'colorX', 'colorY',\n",
        "                            'orientationW', 'orientationX', 'orientationY',\n",
        "                            'orientationZ', 'trackingState'\n",
        "                        ]\n",
        "                        joint_info = {\n",
        "                            k: float(v)\n",
        "                            for k, v in zip(joint_info_key, f.readline().split())\n",
        "                        }\n",
        "                        body_info['jointInfo'].append(joint_info)\n",
        "                    frame_info['bodyInfo'].append(body_info)\n",
        "                skeleton_sequence['frameInfo'].append(frame_info)\n",
        "        # print(\"skeleton_sequence['frameInfo'][30]\", skeleton_sequence['frameInfo'][30])        \n",
        "        # print(\"skeleton_sequence['frameInfo'][29]['bodyInfo'][0]['jointInfo'][11]\", skeleton_sequence['frameInfo'][29]['bodyInfo'][0]['jointInfo'][11])\n",
        "        # print(\"skeleton_sequence['frameInfo'][30]['bodyInfo'][0]['jointInfo'][11]\", skeleton_sequence['frameInfo'][30]['bodyInfo'][0]['jointInfo'][11])        \n",
        "        return skeleton_sequence\n",
        "\n",
        "    #simple_data has a format of [sequence_length , 150]\n",
        "    def read_xyz(self, file, max_body=2, num_joint=25):\n",
        "        seq_info = self._read_skeleton(file)\n",
        "        # print('numBody = ', seq_info['frameInfo'][0]['numBody'])\n",
        "        data = np.zeros((3, seq_info['numFrame'], num_joint, seq_info['frameInfo'][0]['numBody']))  # (3(#xyz), frame_nums, 25(#joints), 2(#people))\n",
        "        for n, f in enumerate(seq_info['frameInfo']):\n",
        "            for m, b in enumerate(f['bodyInfo']):\n",
        "                for j, v in enumerate(b['jointInfo']):\n",
        "                    if m < max_body and j < num_joint:\n",
        "                        data[:, n, j, m] = [v['x'], v['y'], v['z']]\n",
        "                    else:\n",
        "                        pass\n",
        "        # check data exists in 31st frame, 12th joint, 1st body.\n",
        "        # data[#coordinate, #frames, #joints, #body]\n",
        "        # print('data[:,30, 17, 0]', data[:,30, 17, 0])\n",
        "        return data    \n",
        "\n",
        "    def _normal_skeleton(self, data):\n",
        "        #data is in the form of data[#body, #frames, #joints, #coordinate]\n",
        "        #  use as center joint\n",
        "        # center_joint is an array of #body, #frame, #coordinate for 0th joint\n",
        "        center_joint = data[:, :, 0, :]\n",
        "\n",
        "        center_jointx = np.mean(center_joint[:,:, 0] )\n",
        "        center_jointy = np.mean(center_joint[:,:, 1])\n",
        "        center_jointz = np.mean(center_joint[:,:, 2])\n",
        "\n",
        "        center = np.array([center_jointx, center_jointy, center_jointz])\n",
        "        data = data - center\n",
        "\n",
        "        return data\n",
        "\n",
        "    def _rotation(self, data, alpha=0, beta=0):\n",
        "        # rotate the skeleton around x-y axis\n",
        "        r_alpha = alpha * np.pi / 180\n",
        "        r_beta = beta * np.pi / 180\n",
        "\n",
        "        rx = np.array([[1, 0, 0],\n",
        "                       [0, np.cos(r_alpha), -1 * np.sin(r_alpha)],\n",
        "                       [0, np.sin(r_alpha), np.cos(r_alpha)]]\n",
        "                      )\n",
        "\n",
        "        ry = np.array([\n",
        "            [np.cos(r_beta), 0, np.sin(r_beta)],\n",
        "            [0, 1, 0],\n",
        "            [-1 * np.sin(r_beta), 0, np.cos(r_beta)],\n",
        "        ])\n",
        "\n",
        "        r = ry.dot(rx)\n",
        "        data = data.dot(r)\n",
        "\n",
        "        return data\n",
        "\n",
        "    def set_relative_response(self, attention_response=None, arrange_required=False):\n",
        "      #data_xyz is in the shape of [#body, #frames, #coordinate, #joints]\n",
        "      if self.arranged_xyz is not None:\n",
        "        data_xyz = np.transpose(self.arranged_xyz, (0,1,3,2))  #arranged_xyz is [#body, #frames, #joints, #coordinate]\n",
        "      if self.arranged_xyz is None:        \n",
        "        data_xyz = np.transpose(self.xyz, (3, 1, 0, 2))\n",
        "      if attention_response is None:\n",
        "        attention_response = np.ones([self.num_people, self.num_frame, self.num_joints, self.num_coordinate])\n",
        "      #set attention_response in the form of [#body, #frames, #joints, #coordinate] from [#frame, 150 coordinates]\n",
        "      if arrange_required == True:\n",
        "        body1 = attention_response[:,:75]\n",
        "        body2 = attention_response[:,75:]\n",
        "        body1 = body1.reshape(-1, 25, 3)\n",
        "        body2 = body2.reshape(-1, 25, 3)\n",
        "        empty_body = np.zeros(body2.shape)\n",
        "        if np.allclose(body2, empty_body): \n",
        "          print('body2 is empty in attention_response')\n",
        "          attention_response = body1[np.newaxis, ...]\n",
        "        else:           \n",
        "          print('body2 exists in attention_response')\n",
        "          attention_response = np.concatenate((body1, body2), axis=0).reshape(2, -1, 25, 3)\n",
        "      # print('data_xyz[#body, #frames, #coordinate, #joints] = \\n', data_xyz, '\\n')\n",
        "      data_xyz_center = data_xyz[...,0]\n",
        "      # print('data_xyz_center = \\n', data_xyz_center, '\\n')\n",
        "      data_xyz_center_diff = data_xyz - data_xyz_center[..., np.newaxis]\n",
        "      # print('data_xyz_center_diff = \\n', data_xyz_center_diff, '\\n')\n",
        "      energy = np.power(data_xyz_center_diff, 2)\n",
        "      # print('energy [#body, #frames, #coordinate, #joints]= \\n', energy, '\\n')\n",
        "      energy_diff_abs = np.abs(np.diff(energy, axis=1))\n",
        "      # print('energy_diff_abs = \\n', energy_diff_abs, '\\n')\n",
        "      energy_diff_abs_mean = np.mean(energy_diff_abs, axis=3)\n",
        "      # print('energy_diff_abs_mean = \\n', energy_diff_abs_mean, '\\n')\n",
        "      energy_diff_abs_mean_shape = energy_diff_abs_mean.shape\n",
        "      energy_ones = np.ones((energy_diff_abs_mean_shape[0], 1, energy_diff_abs_mean_shape[2]))\n",
        "      #weight_response is in the shape of[#body, #frames, #coordinate]\n",
        "      weight_response = np.append(energy_ones, energy_diff_abs_mean, axis=1)\n",
        "      # print(\"weight_response =\\n\", weight_response, '\\n')\n",
        "      #attention_response is in the form of [#body, #frames, #joints, #coordinate]\n",
        "      #relative_response_xyz is in the form of[#body, #frames, #joints, #coordinate]\n",
        "      relative_response_xyz = attention_response / weight_response[..., np.newaxis, :]\n",
        "      # print('relative_response_xyz = \\n', relative_response_xyz, '\\n')\n",
        "      #self.relative_response is in a shape of [#person, #frames, #joint]\n",
        "      self.relative_response = np.sum(relative_response_xyz, axis=3)\n",
        "      # print('self.relative_response = \\n', self.relative_response, '\\n')\n",
        "\n",
        "      # # this is the case where 0-1 scale on each person. relative_response_max is in a shape of [#person, #frames]\n",
        "      # relative_response_max = np.amax(self.relative_response, axis=2)\n",
        "\n",
        "      # this is the case where 0-1 scale on both people. relative_response_max is in a shape of [#frames]\n",
        "      relative_response_max = np.amax(np.amax(self.relative_response, axis=2), axis=0)\n",
        "\n",
        "      #self.scaled_relative_response is in a shape of [#person, #frames, #joint].It provides 0-1 scaled relative response\n",
        "      self.scaled_relative_response = self.relative_response / relative_response_max[np.newaxis, : , np.newaxis]\n",
        "\n",
        "    def visual_skeleton_animate(self, use_relative_response=False, scattersize_max=10, frame_idx_total=None, sleep_time=0.5, figsize=(10,10), \\\n",
        "                                is_image_save=True, skeleton_color='r', joint_color='yellow'):\n",
        "        #data becomes data[#body, #frames, #joints, #coordinate] from [#coordinate, #frames, #joints, #body]\n",
        "        if self.arranged_xyz is not None:\n",
        "          data = self.arranged_xyz\n",
        "        if self.arranged_xyz is None:        \n",
        "          data = np.transpose(self.xyz, (3, 1, 2, 0))\n",
        "        \n",
        "        num_people = data.shape[0]\n",
        "        # print('num_people =', num_people)\n",
        "        fig = plt.figure(figsize=figsize)\n",
        "        axs = fig.add_subplot(projection='3d')\n",
        "\n",
        "        # data rotation\n",
        "        if (self.x_rotation is not None) or (self.y_rotation is not None):\n",
        "\n",
        "            if self.x_rotation > 180 or self.y_rotation > 180:\n",
        "                raise Exception(\"rotation angle should be less than 180.\")\n",
        "\n",
        "            else:\n",
        "                data = self._rotation(data, self.x_rotation, self.y_rotation)\n",
        "\n",
        "        # data normalization\n",
        "        data = self._normal_skeleton(data)\n",
        "\n",
        "        data_flatten_xyz = data.reshape((-1,3))\n",
        "        xyz_max = np.amax(data_flatten_xyz, axis=0)\n",
        "        xyz_min = np.amin(data_flatten_xyz, axis=0)\n",
        "        xz_range = [np.amin(xyz_min[[0,2]], axis=None), np.amax(xyz_max[[0,2]], axis=None)]\n",
        "        y_range =  [xyz_min[1], xyz_max[1]]\n",
        "        xyz_range = [np.amin(xyz_min, axis=None), np.amax(xyz_max, axis=None)]\n",
        "\n",
        "        # show every frame 3d skeleton\n",
        "        # realsimulation\n",
        "        if frame_idx_total is None:\n",
        "          frame_idx_total = range(data.shape[1])\n",
        "        else:\n",
        "          frame_idx_total = frame_idx_total\n",
        "        \n",
        "        idx_axs = 1\n",
        "        test_z_min = 999\n",
        "        test_x_plot = None\n",
        "        test_y_plot = None\n",
        "        test_z_plot = None\n",
        "        for frame_idx in frame_idx_total:\n",
        "            axs.set_facecolor(\"none\")\n",
        "            #range should be adjusted\n",
        "            #the screen length of x,y,z are same regardless of your xlim, ylim, zlim. Therefore, it is important to put the smiliar values in xlim, ylim, zlim to keep the ratio 1:1:1.\n",
        "            axs.set_xlim3d(xyz_range)\n",
        "            # here, ylim3d corresponds to z (depth) in the data coordinate (the graph label it as Z)\n",
        "            axs.set_ylim3d(xyz_range)\n",
        "            # here, zlim3d corresponds to y (height) in the data coordinate (the graph label it as Y)\n",
        "            # you replace the min of zlim to actual y_range[0] to keep the feet of people on the floor\n",
        "            axs.set_zlim3d([y_range[0], xyz_range[1]])\n",
        "\n",
        "            #define ticks              \n",
        "            tick_perturb = 0.01\n",
        "            # axs.set_xticks(np.arange(-1 - tick_perturb, 0.5 + tick_perturb, step=0.5))\n",
        "            # axs.set_yticks(np.arange(-0.5 - tick_perturb, 1 + tick_perturb, step=0.5))\n",
        "            # axs.set_zticks(np.arange(-0.8 - tick_perturb, 0.8 + tick_perturb, step=0.4))\n",
        "\n",
        "            # for each_person in range(1):\n",
        "            for each_person in range(num_people):\n",
        "              #data is in shape of [#of people, #frames, #joints, coordinte]\n",
        "              x = data[each_person, frame_idx, :, 0]\n",
        "              y = data[each_person, frame_idx, :, 1]\n",
        "              z = data[each_person, frame_idx, :, 2]\n",
        "              # print(\"frame_idx={}, x={},x.size={}, \\n y={}, y.size={}, \\n z={},z.size={}\".format(frame_idx, x, x.size, y, y.size, z, z.size))\n",
        "\n",
        "              #drawing skeletons_in_body in one axs\n",
        "              for idx_part, part in enumerate(skeletons_in_body):\n",
        "                  #each part is trunk, arm, leg\n",
        "                  #x_plot is x values in trunk or arm or leg. array of numbers \n",
        "                  x_plot = x[part]\n",
        "                  y_plot = y[part]\n",
        "                  z_plot = z[part]\n",
        "                  if test_z_min > np.amin(z_plot):\n",
        "                    test_z_min = np.amin(z_plot)\n",
        "                  if np.amin(z_plot) < -0.336:\n",
        "                    test_x_plot = x_plot\n",
        "                    test_y_plot = y_plot\n",
        "                    test_z_plot = z_plot\n",
        "                  if use_relative_response == False or self.relative_response is None:\n",
        "                    #trunk case. increase the circle size\n",
        "                    if idx_part ==0:\n",
        "                      scattersize_joint = np.ones(x_plot.size) * 10 * scattersize_max\n",
        "                    else:\n",
        "                      scattersize_joint = np.ones(x_plot.size) * scattersize_max\n",
        "                  #formula for relative_response to scattersize_joint\n",
        "                  else:\n",
        "                    #self.scaled_relative_response provides 0-1 scaled relative response\n",
        "                    #scattersize_joint is in shape of [# of joints]\n",
        "                    scattersize_joint = self.scaled_relative_response[each_person, frame_idx, part] * scattersize_max\n",
        "                  # the ratio of elements in scattersize_joint is the ratio of relative response\n",
        "                  # print('scattersize_joint = ', scattersize_joint)\n",
        "                  axs.plot(x_plot, z_plot, y_plot, color=skeleton_color, marker='o', markersize=0.1, markerfacecolor=joint_color)\n",
        "                  axs.scatter(x_plot, z_plot, y_plot, s=scattersize_joint, c=joint_color)\n",
        "\n",
        "            #decorate the axs\n",
        "            axs.set_xlabel('X')\n",
        "            axs.set_ylabel('Z')\n",
        "            axs.set_zlabel('Y')\n",
        "            axs.set_title('{} frame'.format(frame_idx))\n",
        "            if (self.save_path is not None) and (is_image_save == True):\n",
        "                # print statement interrupt the figure. So no use if you want to animate the figure \n",
        "                # print(\"save_path frame_idx = \", frame_idx)\n",
        "                save_pth = os.path.join(self.save_path, '{}.png'.format(frame_idx))\n",
        "                plt.savefig(save_pth)\n",
        "                save_check_period = 0.01\n",
        "                while (not(os.path.exists(save_pth))):\n",
        "                  sleep(save_check_period)\n",
        "                with open(save_pth, 'r') as skeleton_file:\n",
        "                  #  print('passed both os.path.exists and open(file)')\n",
        "                  pass\n",
        "                # print('save_pth = {}, png saved? = {}'.format(save_pth, os.path.exists(save_pth)))\n",
        "            #animation part\n",
        "            display.display(plt.gcf())            \n",
        "            sleep(sleep_time)\n",
        "            #prepare the next plot\n",
        "            #remove the current axs for the next plot\n",
        "            if (frame_idx != frame_idx_total[-1]):\n",
        "              display.clear_output(wait=True)\n",
        "              plt.cla()\n",
        "            idx_axs += 1\n",
        "        \n",
        "        #after showing plot of each frame in animation, you only leave the last frame image. So plt.clf() will remove the regualr axs.plot() image coming at the last\n",
        "        plt.clf()\n",
        "        # print('test_z_min = ', test_z_min)\n",
        "        # print('test_x_plot = ', test_x_plot)\n",
        "        # print('test_y_plot = ', test_y_plot)\n",
        "        # print('test_z_plot = ', test_z_plot)\n",
        "        # print('xyz_max = ', xyz_max)\n",
        "        # print('xyz_min = ', xyz_min)\n",
        "        # print('xz_range =', xz_range)\n",
        "        # print('y_range =', y_range)\n",
        "\n",
        "#??? I am not sure the scattersize becomes the ratio of area or volume\n",
        "#??? maybe draw skeleton in 2D and show the relative_response\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrgOh49DWbLO"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA2T1RgT3IRC"
      },
      "source": [
        "#################################### test test #################################################\n",
        "#################################### test test #################################################\n",
        "#################################### test test #################################################\n",
        "#################################### test test #################################################\n",
        "class test_visual():\n",
        "  def __init__(self, xyz):\n",
        "    #self.xyz is in the shape of [#coordinate, #frames, #joints, #body]\n",
        "    self.xyz = xyz\n",
        "    self.num_coordinate = self.xyz.shape[0]\n",
        "    self.num_frame = self.xyz.shape[1]\n",
        "    self.num_joints = self.xyz.shape[2]\n",
        "    self.num_people = self.xyz.shape[3]\n",
        "    self.relative_response =None\n",
        "    self.scaled_relative_response = None\n",
        "\n",
        "  def set_relative_response(self, attention_response=None):\n",
        "    #data_xyz is in the shape of [#body, #frames, #coordinate, #joints]\n",
        "    data_xyz = np.transpose(self.xyz, (3, 1, 0, 2))\n",
        "    if attention_response is None:\n",
        "      attention_response = np.ones([self.num_people, self.num_frame, self.num_joints, self.num_coordinate])\n",
        "    print('data_xyz[#body, #frames, #coordinate, #joints] = \\n', data_xyz, '\\n')\n",
        "    data_xyz_center = data_xyz[...,0]\n",
        "    print('data_xyz_center = \\n', data_xyz_center, '\\n')\n",
        "    data_xyz_center_diff = data_xyz - data_xyz_center[..., np.newaxis]\n",
        "    print('data_xyz_center_diff = \\n', data_xyz_center_diff, '\\n')\n",
        "    energy = np.power(data_xyz_center_diff, 2)\n",
        "    print('energy [#body, #frames, #coordinate, #joints]= \\n', energy, '\\n')\n",
        "    energy_diff_abs = np.abs(np.diff(energy, axis=1))\n",
        "    print('energy_diff_abs = \\n', energy_diff_abs, '\\n')\n",
        "    energy_diff_abs_mean = np.mean(energy_diff_abs, axis=3)\n",
        "    print('energy_diff_abs_mean = \\n', energy_diff_abs_mean, '\\n')\n",
        "    energy_diff_abs_mean_shape = energy_diff_abs_mean.shape\n",
        "    energy_ones = np.ones((energy_diff_abs_mean_shape[0], 1, energy_diff_abs_mean_shape[2]))\n",
        "    #weight_response is in the shape of[#body, #frames, #coordinate]\n",
        "    weight_response = np.append(energy_ones, energy_diff_abs_mean, axis=1)\n",
        "    print(\"weight_response =\\n\", weight_response, '\\n')\n",
        "    #attention_response is in the form of [#body, #frames, #joints, #coordinate]\n",
        "    #relative_response_xyz is in the form of[#body, #frames, #joints, #coordinate]\n",
        "    relative_response_xyz = attention_response / weight_response[..., np.newaxis, :]\n",
        "    print('relative_response_xyz = \\n', relative_response_xyz, '\\n')\n",
        "    #self.relative_response is in a shape of [#person, #frames, #joint]\n",
        "    self.relative_response = np.sum(relative_response_xyz, axis=3)\n",
        "    print('self.relative_response = \\n', self.relative_response, '\\n')\n",
        "\n",
        "    # # this is the case where 0-1 scale on each person. relative_response_max is in a shape of [#person, #frames]\n",
        "    # relative_response_max = np.amax(self.relative_response, axis=2)\n",
        "\n",
        "    # this is the case where 0-1 scale on both people. relative_response_max is in a shape of [#frames]\n",
        "    relative_response_max = np.amax(np.amax(self.relative_response, axis=2), axis=0)\n",
        "\n",
        "    #self.scaled_relative_response is in a shape of [#person, #frames, #joint].It provides 0-1 scaled relative response\n",
        "    self.scaled_relative_response = self.relative_response / relative_response_max[np.newaxis, : , np.newaxis]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pVNC_Ec4d6a"
      },
      "source": [
        "#self.xyz is in the shape of [#coordinate, #frames, #joints, #body]\n",
        "# test_xyz = np.random.rand(3, 3, 3, 2)\n",
        "#used to find out the weight\n",
        "test_xyz = np.ones((3, 3, 3, 2))\n",
        "test_xyz[:,1,:,:]=2\n",
        "test_xyz[:,:,0,:]=3\n",
        "print('test_xyz = \\n', test_xyz)\n",
        "#attention_response is in the form of [#body, #frames, #joints, #coordinate]\n",
        "# attention_response = np.ones((2, 3, 3, 3))\n",
        "# attention_response = [[[[1, 1, 1,],\n",
        "#    [1, 1, 1,],\n",
        "#    [1, 1, 1,]],\n",
        "\n",
        "#   [[1, 1, 1,],\n",
        "#    [1, 1, 1,],\n",
        "#    [1, 1, 1,]],\n",
        "\n",
        "#   [[1, 1, 1,],\n",
        "#    [1, 1, 1,],\n",
        "#    [1, 1, 1,]]],\n",
        "\n",
        "\n",
        "#  [[[100, 10, 10,],\n",
        "#    [10, 100, 10,],\n",
        "#    [10, 10, 100,]],\n",
        "\n",
        "#   [[100, 10, 10,],\n",
        "#    [100, 10, 10,],\n",
        "#    [100, 10, 10,]],\n",
        "\n",
        "#   [[10, 10, 100,],\n",
        "#    [10, 10, 100,],\n",
        "#    [10, 10, 100,]]]]\n",
        "\n",
        "attention_response = [[[[1, 1, 1,],\n",
        "   [1, 1, 1,],\n",
        "   [1, 1, 1,]],\n",
        "\n",
        "  [[1, 1, 1,],\n",
        "   [1, 1, 1,],\n",
        "   [1, 1, 1,]],\n",
        "\n",
        "  [[1, 1, 1,],\n",
        "   [1, 1, 1,],\n",
        "   [1, 1, 1,]]],\n",
        "\n",
        "\n",
        " [[[1, 1, 1,],\n",
        "   [1, 1, 1,],\n",
        "   [1, 1, 1,]],\n",
        "\n",
        "  [[1, 1, 1,],\n",
        "   [1, 1, 1,],\n",
        "   [1, 1, 1,]],\n",
        "\n",
        "  [[1, 1, 1,],\n",
        "   [1, 1, 1,],\n",
        "   [1, 1, 1,]]]]\n",
        "\n",
        "print('attention_response = \\n', attention_response, '\\n')\n",
        "test_a = test_visual(test_xyz)\n",
        "test_a.set_relative_response(attention_response)\n",
        "#self.relative_response is in a shape of [#person, #frames, #joint] from [#body, #frames, #joints, #coordinate]\n",
        "#self.scaled_relative_response is in a shape of [#person, #frames, #joint]\n",
        "print('test_a.scaled_relative_response = \\n', test_a.scaled_relative_response)\n",
        "#let's test more cases"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBNSyuyqm5Mp"
      },
      "source": [
        "#self.xyz is in the shape of [#coordinate, #frames, #joints, #body]\n",
        "# test_xyz = np.random.rand(3, 3, 3, 2)\n",
        "#used to find out the weight\n",
        "test_xyz = np.ones((3, 3, 3, 2))\n",
        "test_xyz[:,1,:,:]=2\n",
        "test_xyz[:,:,0,:]=3\n",
        "print('test_xyz = \\n', test_xyz)\n",
        "#attention_response is in the form of [#body, #frames, #joints, #coordinate]\n",
        "# attention_response = np.ones((2, 3, 3, 3))\n",
        "test_a = test_visual(test_xyz)\n",
        "test_a.set_relative_response()\n",
        "#self.relative_response is in a shape of [#person, #frames, #joint] from [#body, #frames, #joints, #coordinate]\n",
        "#self.scaled_relative_response is in a shape of [#person, #frames, #joint]\n",
        "print('test_a.scaled_relative_response = \\n', test_a.scaled_relative_response)\n",
        "#let's test more cases"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzwBrjsEPEk1"
      },
      "source": [
        "test_a = np.array([[[1,2,3],\n",
        "                    [4,5,6]],\n",
        "                   [[7,8,9],\n",
        "                    [10,11,12]]])\n",
        "test_b = test_a.reshape((-1, 3))\n",
        "test_c = np.ones((2,1,3))\n",
        "print('test_a = \\n,', test_a, '\\n')\n",
        "print('test_a.shape = ', test_a.shape)\n",
        "print('test_b = \\n', test_b, '\\n')\n",
        "print('test_c = \\n', test_c, '\\n')\n",
        "test_d = np.append(test_c, test_a, axis=1)\n",
        "print('test_d (test_a + test_c) = \\n', test_d, '\\n')\n",
        "print('test_d.shape = \\n', test_d.shape)\n",
        "print('amax =', np.amax(np.amax(test_a, axis=0), axis=0))\n",
        "print('amin =', np.amin(np.amin(test_a, axis=0), axis=0))\n",
        "print('amax =', np.amax(test_b, axis=None))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zz4zHQ5vqaiJ"
      },
      "source": [
        "test_a = np.array([[[1,2,3],\n",
        "                    [4,5,6]],\n",
        "                   [[7,8,9],\n",
        "                    [1,2,3]]])\n",
        "test_c = np.ones((2,1,3))\n",
        "print('test_a = \\n,', test_a, '\\n')\n",
        "print('test_a.shape = ', test_a.shape)\n",
        "print('test_c = \\n', test_c, '\\n')\n",
        "test_d = np.append(test_c, test_a, axis=1)\n",
        "print('test_d (test_a + test_c) = \\n', test_d, '\\n')\n",
        "print('test_d.shape = \\n', test_d.shape)\n",
        "\n",
        "test_energy = np.diff(test_a, axis=1)\n",
        "print('test_energy = \\n', test_energy, '\\n test_energy.shape= ', test_energy.shape)\n",
        "test_energy_appended = np.append(test_c, test_energy, axis=1)\n",
        "print('test_energy_appended = \\n', test_energy_appended)\n",
        "test_energy_mean = np.mean(test_energy_appended, axis=2)\n",
        "print('test_energy_mean \\n', test_energy_mean)\n",
        "\n",
        "print('np.power(test_a, 2) = \\n', np.power(test_a, 2))\n",
        "test_e = test_a[..., 0]\n",
        "print('test_e = \\n', test_e, 'test_e.shape = ', test_e.shape)\n",
        "\n",
        "test_f = test_a - test_e[..., np.newaxis]\n",
        "print('test_f = \\n', test_f, 'test_f.shape = ', test_f.shape)\n",
        "print('test_a = \\n,', test_a, '\\n')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHVAUrEvSuCV"
      },
      "source": [
        "#2 people data\n",
        "sk = Draw3DSkeleton(\"S001C001P001R001A060.skeleton\", './test_result')\n",
        "\n",
        "relative_response = np.ones(25)\n",
        "trunk_joints = np.array([0, 1, 20, 2, 3])\n",
        "relative_response[trunk_joints] = 10\n",
        "\n",
        "# frame_idx_total = np.array([4, 50, 70])\n",
        "# sk.visual_skeleton_animate(relative_response=relative_response, scattersize_max=100, frame_idx_total=frame_idx_total, sleep_time=0.2)\n",
        "\n",
        "# sk.visual_skeleton_animate(relative_response=relative_response, scattersize_max=100, sleep_time=0.5)\n",
        "\n",
        "sk.visual_skeleton_animate(use_relative_response=False, scattersize_max=10, sleep_time=0.5, is_image_save = False )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebsCqRWaoQeB"
      },
      "source": [
        "#2 people data\n",
        "sk = Draw3DSkeleton(\"S001C001P001R001A060.skeleton\", './test_result')\n",
        "#attention_response is in the form of [#body, #frames, #joints, #coordinate]\n",
        "attention_response = sk.set_relative_response(attention_response=None)\n",
        "sk.visual_skeleton_animate(use_relative_response=True, scattersize_max=50, sleep_time=0.5, is_image_save = True )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxBq-VLYQ-uM"
      },
      "source": [
        "sk = Draw3DSkeleton(\"S001C001P001R002A035.skeleton\", './test_result')\n",
        "# sk.visual_skeleton(relative_response=None, scattersize_max=10)\n",
        "relative_response = np.ones(25)\n",
        "trunk_joints = np.array([0, 1, 20, 2, 3])\n",
        "relative_response[trunk_joints] = 10\n",
        "\n",
        "#method1\n",
        "# frame_idx_total = np.array([4, 50, 70])\n",
        "# sk.visual_skeleton_animate(relative_response=relative_response, scattersize_max=100, frame_idx_total=frame_idx_total, sleep_time=0.2)\n",
        "#method2\n",
        "# sk.visual_skeleton_animate(relative_response=relative_response, scattersize_max=100, sleep_time=0.5)\n",
        "#method3\n",
        "# sk.visual_skeleton_animate(relative_response=relative_response, scattersize_max=100, sleep_time=0.5, is_image_save = False )\n",
        "#method4 using attention response\n",
        "attention_response = sk.set_relative_response(attention_response=None)\n",
        "sk.visual_skeleton_animate(use_relative_response=True, scattersize_max=50, sleep_time=0.5, is_image_save=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14dLFTgiTeQi",
        "outputId": "1db90fc1-c009-4a37-bb20-96045af30501"
      },
      "source": [
        "data_from_net = skeleton_cv_crd[34]\r\n",
        "body1 = data_from_net[:,:75]\r\n",
        "body2 = data_from_net[:,75:]\r\n",
        "body1 = body1.reshape(-1, 25, 3)\r\n",
        "print(body1.shape)\r\n",
        "body2 = body2.reshape(-1, 25, 3)\r\n",
        "print(body2.shape)\r\n",
        "empty_body = np.zeros(body2.shape)\r\n",
        "print(empty_body.shape)\r\n",
        "if np.allclose(body2, empty_body): \r\n",
        "  print('body2 is empty')\r\n",
        "  arranged_xyz = body1[np.newaxis, ...]\r\n",
        "else:           \r\n",
        "  print('body2 exists')\r\n",
        "  arranged_xyz = np.concatenate((body1, body2), axis=0).reshape(2, -1, 25, 3)\r\n",
        "print('arranged_xyz.shape = ', arranged_xyz.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(233, 25, 3)\n",
            "(233, 25, 3)\n",
            "(233, 25, 3)\n",
            "body2 is empty\n",
            "arranged_xyz.shape =  (1, 233, 25, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ2OiZnvSPWc"
      },
      "source": [
        "################### use the data from AttG-GRU ######################\r\n",
        "################### use the data from AttG-GRU ######################\r\n",
        "################### use the data from AttG-GRU ######################\r\n",
        "cut_frame_idx = 200\r\n",
        "# sample_idx = 214  #bow\r\n",
        "sample_idx = 56\r\n",
        "path_test_result = './test_result'\r\n",
        "path_rest_result_plain = './test_result_plain'\r\n",
        "#cv case\r\n",
        "data_from_net = skeleton_cv_crd[sample_idx][:cut_frame_idx] #no more frame after 60.\r\n",
        "#cs case\r\n",
        "# data_from_net = skeleton_cs_crd[sample_idx][:cut_frame_idx] #no more frame after 60.\r\n",
        "sk = Draw3DSkeleton(file=data_from_net, save_path=path_test_result, is_file_txt=False)\r\n",
        "\r\n",
        "# use the aritifical relative response\r\n",
        "# relative_response = np.ones(25)\r\n",
        "# trunk_joints = np.array([0, 1, 20, 2, 3])\r\n",
        "# relative_response[trunk_joints] = 10\r\n",
        "\r\n",
        "#use generated relative response\r\n",
        "attention_response = skeleton_cv_att[sample_idx][:cut_frame_idx]\r\n",
        "\r\n",
        "sk_plain = Draw3DSkeleton(file=attention_response, save_path=path_rest_result_plain, is_file_txt=False)\r\n",
        "\r\n",
        "#method1\r\n",
        "# frame_idx_total = np.array([4, 50, 70])\r\n",
        "# sk.visual_skeleton_animate(relative_response=relative_response, scattersize_max=100, frame_idx_total=frame_idx_total, sleep_time=0.2)\r\n",
        "#method2\r\n",
        "# sk.visual_skeleton_animate(relative_response=relative_response, scattersize_max=100, sleep_time=0.5)\r\n",
        "#method3: using artificial relative response (make head big or something like that)\r\n",
        "# sk.visual_skeleton_animate(relative_response=relative_response, scattersize_max=100, sleep_time=0.5, is_image_save = False )\r\n",
        "#method4: using generated attention response\r\n",
        "# sk.set_relative_response(attention_response=attention_response, arrange_required=True)\r\n",
        "# sk.visual_skeleton_animate(use_relative_response=True, scattersize_max=200, sleep_time=0.5, is_image_save=True)\r\n",
        "#method5: using generated attention response\r\n",
        "sk.set_relative_response(attention_response=attention_response, arrange_required=True)\r\n",
        "sk.visual_skeleton_animate(use_relative_response=True, scattersize_max=300, sleep_time=0.1, is_image_save=True, skeleton_color='r', joint_color='blue')\r\n",
        "#method6: using aritificial all one response \r\n",
        "# sk_plain.set_relative_response(attention_response=None, arrange_required=False)\r\n",
        "# sk_plain.visual_skeleton_animate(use_relative_response=True, scattersize_max=50, sleep_time=0.5, is_image_save=True, skeleton_color='r', joint_color='blue')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr_SUif3gdPE"
      },
      "source": [
        "sk = Draw3DSkeleton(\"S001C001P004R002A008.skeleton\", './test_result')\n",
        "# sk.visual_skeleton(relative_response=None, scattersize_max=10)\n",
        "relative_response = np.ones(25)\n",
        "trunk_joints = np.array([0, 1, 20, 2, 3])\n",
        "relative_response[trunk_joints] = 10\n",
        "\n",
        "frame_idx_total = np.array([4,14,34])\n",
        "sk.visual_skeleton_animate(relative_response=relative_response, scattersize_max=100, frame_idx_total=frame_idx_total, sleep_time=0.2)\n",
        "\n",
        "# sk.visual_skeleton_animate(relative_response=relative_response, scattersize_max=100, sleep_time=0.5)\n",
        "\n",
        "# sk.visual_skeleton_animate(relative_response=relative_response, scattersize_max=100, sleep_time=0.5, is_image_save = False )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8LY_p2bSI-a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQUzz19FfRfk"
      },
      "source": [
        "# sk = Draw3DSkeleton(\"S001C001P004R002A008.skeleton\", './test_result')\n",
        "# # sk.visual_skeleton(relative_response=None, scattersize_max=10)\n",
        "# relative_response = np.ones(25)\n",
        "# trunk_joints = np.array([0, 1, 20, 2, 3])\n",
        "# relative_response[trunk_joints] = 10\n",
        "# frame_idx_total = np.array([1, 10, 20, 30, 40, 50])\n",
        "# sk.visual_skeleton(relative_response=relative_response, scattersize_max=100, frame_idx_total=frame_idx_total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDcaaNd6JjEa"
      },
      "source": [
        "\n",
        "    # default horizon, vertical test \n",
        "    # sk2 = Draw3DSkeleton(\"S001C001P004R002A008.skeleton\", './test_result', init_horizon=0, init_vertical=0)\n",
        "    # sk2.visual_skeleton()\n",
        "    # sk3 = Draw3DSkeleton(\"S001C001P004R002A008.skeleton\", './test_result', init_horizon=-45, init_vertical=0)\n",
        "    # sk3.visual_skeleton()\n",
        "    # sk4 = Draw3DSkeleton(\"S001C001P004R002A008.skeleton\", './test_result', init_horizon=0, init_vertical=20)\n",
        "    # sk4.visual_skeleton()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ph_RcZaWLCwm"
      },
      "source": [
        "x = np.array([1,2,3])\n",
        "y = np.array([-1,0,1])\n",
        "markersize_const = 8\n",
        "markersize_array = np.array([5,10,20]) * markersize_const\n",
        "print('markersize_array = ', markersize_array)\n",
        "fig, ax = plt.subplots(1,1,figsize=(14,7))\n",
        "ax.plot(x,y, marker='o', markersize=0.1)\n",
        "# plt.xticks([1,2,3])\n",
        "ax.set_xticks(np.arange(x[0], x[-1]+0.01, step=0.3))\n",
        "ax.set_yticks(np.arange(y[0], y[-1]+0.01, step=0.3))\n",
        "ax.scatter(x,y, s=markersize_array, c='yellow')\n",
        "for i in range(50):\n",
        "  ax.scatter(x[2],y[2], s=markersize_array[2], c='yellow')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elnfF9XmLk1E"
      },
      "source": [
        "x_array = np.array(range(10))\n",
        "y_array = np.array(range(10))*-1 +5\n",
        "z_array = np.array(range(10))\n",
        "plt.ion()\n",
        "fig = plt.figure(figsize=(14,7))\n",
        "axs = fig.add_subplot(2,2,1, projection='3d')\n",
        "axs.plot(x_array, y_array, z_array)\n",
        "axs = fig.add_subplot(2,2,2, projection='3d')\n",
        "axs.plot(y_array, x_array, z_array)\n",
        "axs = fig.add_subplot(2,2,3, projection='3d')\n",
        "axs.plot(z_array, y_array, x_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yceGzX2T04LX"
      },
      "source": [
        "from IPython import display\n",
        "from time import sleep\n",
        "x_array = np.array(range(10))\n",
        "y_array = np.array(range(10))*-1+5\n",
        "z_array = np.array(range(10))*-2+5\n",
        "fig = plt.figure(figsize=(14,7))\n",
        "axs = fig.add_subplot(projection='3d')\n",
        "axs.plot(x_array, y_array, z_array)\n",
        "print('111')\n",
        "display.display(plt.gcf())\n",
        "print('aaa')\n",
        "sleep(2)\n",
        "plt.cla()\n",
        "display.clear_output(wait=True)\n",
        "axs.plot(y_array, x_array, z_array)\n",
        "display.display(plt.gcf())\n",
        "print('bbb')\n",
        "sleep(2)\n",
        "# plt.clf()\n",
        "print('ccc')\n",
        "#if therre is no plt.clf(), axs.plot will be shown at the end of the execution. Therefore, the plot will appear after print('ccc')\n",
        "\n",
        "\n",
        "# display.clear_output(wait=True)\n",
        "# sleep(2)\n",
        "# display.clear_output()\n",
        "# axs.plot(z_array, y_array, x_array)\n",
        "\n",
        "# display.display(axs.plot(x_array, y_array, z_array))\n",
        "# display.clear_output()\n",
        "# sleep(1)\n",
        "# display.display(axs.plot(y_array, x_array, z_array))\n",
        "# display.clear_output()\n",
        "# axs = fig.add_subplot(2,2,3, projection='3d')\n",
        "# axs.plot(z_array, y_array, x_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BW1XQq95Cj2U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}